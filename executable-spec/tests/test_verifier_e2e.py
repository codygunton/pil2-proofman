"""End-to-end tests for STARK proof verification.

Tests that the Python verifier correctly verifies proofs generated by
the Python prover. This validates the complete STARK verification flow
including Merkle tree verification.
"""

import pytest
import numpy as np
from pathlib import Path
from typing import Dict, Any, List, Optional

from protocol.setup_ctx import SetupCtx, FIELD_EXTENSION
from protocol.steps_params import StepsParams
from primitives.transcript import Transcript
from protocol.prover import gen_proof
from protocol.verifier import stark_verify
from primitives.transcript import Transcript
from primitives.merkle_tree import HASH_SIZE


TEST_DATA_DIR = Path(__file__).parent / "test-data"

# AIR configurations (same as test_stark_e2e.py)
AIR_CONFIGS = {
    'simple': {
        'test_vector': 'simple-left.json',
        'starkinfo': '../../pil2-components/test/simple/build/provingKey/build/Simple/airs/SimpleLeft/air/SimpleLeft.starkinfo.json',
        'expressions_bin': '../../pil2-components/test/simple/build/provingKey/build/Simple/airs/SimpleLeft/air/SimpleLeft.bin',
    },
    'lookup': {
        'test_vector': 'lookup2-12.json',
        'starkinfo': '../../pil2-components/test/lookup/build/provingKey/lookup/Lookup/airs/Lookup2_12/air/Lookup2_12.starkinfo.json',
        'expressions_bin': '../../pil2-components/test/lookup/build/provingKey/lookup/Lookup/airs/Lookup2_12/air/Lookup2_12.bin',
    },
    'permutation': {
        'test_vector': 'permutation1-6.json',
        'starkinfo': '../../pil2-components/test/permutation/build/provingKey/permutation/Permutation/airs/Permutation1_6/air/Permutation1_6.starkinfo.json',
        'expressions_bin': '../../pil2-components/test/permutation/build/provingKey/permutation/Permutation/airs/Permutation1_6/air/Permutation1_6.bin',
    },
}


def load_test_vectors(air_name: str) -> Optional[Dict[str, Any]]:
    """Load test vectors for an AIR."""
    import json
    config = AIR_CONFIGS.get(air_name)
    if not config:
        return None

    test_vector_path = TEST_DATA_DIR / config['test_vector']
    if not test_vector_path.exists():
        return None

    with open(test_vector_path) as f:
        return json.load(f)


def load_setup_ctx(air_name: str) -> Optional[SetupCtx]:
    """Load SetupCtx for an AIR."""
    config = AIR_CONFIGS.get(air_name)
    if not config:
        return None

    base_dir = Path(__file__).parent
    starkinfo_path = base_dir / config['starkinfo']
    expressions_bin_path = base_dir / config['expressions_bin']

    if not starkinfo_path.exists() or not expressions_bin_path.exists():
        return None

    return SetupCtx.from_files(str(starkinfo_path), str(expressions_bin_path))


def create_fresh_transcript(stark_info, vectors: dict) -> Transcript:
    """Create a fresh transcript with global_challenge (if any)."""
    transcript = Transcript(
        arity=stark_info.starkStruct.transcriptArity,
        custom=stark_info.starkStruct.merkleTreeCustom
    )

    global_challenge = vectors['inputs'].get('global_challenge', [])
    if global_challenge:
        transcript.put(global_challenge)

    return transcript


def create_params_from_vectors(stark_info, vectors: dict) -> StepsParams:
    """Create StepsParams initialized from test vectors."""
    from primitives.ntt import NTT

    inputs = vectors['inputs']

    N = 1 << stark_info.starkStruct.nBits
    N_ext = 1 << stark_info.starkStruct.nBitsExt
    n_constants = inputs['n_constants']

    # Calculate total trace buffer size
    trace_size = 0
    for section in ['cm1', 'cm2', 'cm3']:
        if section in stark_info.mapSectionsN:
            offset = stark_info.mapOffsets.get((section, False), 0)
            size = N * stark_info.mapSectionsN[section]
            trace_size = max(trace_size, offset + size)

    # Allocate trace and copy witness
    witness_trace_data = np.array(inputs['witness_trace'], dtype=np.uint64)
    trace = np.zeros(trace_size, dtype=np.uint64)
    trace[:len(witness_trace_data)] = witness_trace_data

    # Convert constant polynomials
    const_pols = np.array(inputs['const_pols'], dtype=np.uint64)

    # Extend constant polynomials
    ntt = NTT(N)
    const_pols_extended = ntt.extend_pol(const_pols, N_ext, N, n_constants)

    # Allocate challenges buffer
    challenges = np.zeros(len(stark_info.challengesMap) * 3, dtype=np.uint64)

    params = StepsParams(
        trace=trace,
        auxTrace=np.zeros(stark_info.mapTotalN, dtype=np.uint64),
        publicInputs=np.zeros(max(1, stark_info.nPublics), dtype=np.uint64),
        challenges=challenges,
        evals=np.zeros(len(stark_info.evMap) * 3, dtype=np.uint64),
        airValues=np.zeros(max(1, stark_info.airValuesSize * 3), dtype=np.uint64),
        airgroupValues=np.zeros(max(1, stark_info.airgroupValuesSize * 3), dtype=np.uint64),
        constPols=const_pols,
        constPolsExtended=const_pols_extended,
    )

    return params


def proof_to_jproof(proof: Dict, stark_info, starks) -> Dict[str, Any]:
    """Convert Python proof format to jproof format expected by verifier.

    Args:
        proof: Proof dictionary from gen_proof()
        stark_info: STARK configuration
        starks: Starks instance (for accessing trees)

    Returns:
        jproof dictionary in verifier format
    """
    jproof = {}

    # Stage roots
    for i, root in enumerate(proof['roots']):
        jproof[f"root{i + 1}"] = [int(r) for r in root]

    # Evaluations (reshape to triplets)
    n_evals = len(stark_info.evMap)
    evals_flat = proof['evals']
    jproof['evals'] = []
    for i in range(n_evals):
        triplet = [int(evals_flat[i * 3 + j]) for j in range(3)]
        jproof['evals'].append(triplet)

    # AIR group values
    airgroup_values = proof['airgroup_values']
    n_airgroup = len(stark_info.airgroupValuesMap)
    jproof['airgroupvalues'] = []
    for i in range(n_airgroup):
        triplet = [int(airgroup_values[i * 3 + j]) for j in range(3)]
        jproof['airgroupvalues'].append(triplet)

    # AIR values
    air_values = proof['air_values']
    jproof['airvalues'] = []
    a = 0
    for i in range(len(stark_info.airValuesMap)):
        if stark_info.airValuesMap[i].stage == 1:
            jproof['airvalues'].append([int(air_values[a])])
            a += 1
        else:
            triplet = [int(air_values[a + j]) for j in range(3)]
            jproof['airvalues'].append(triplet)
            a += 3

    # Nonce
    jproof['nonce'] = proof['nonce']

    # Final polynomial (flat list of FIELD_EXTENSION elements)
    fri_proof = proof['fri_proof']
    final_pol_flat = fri_proof.final_pol
    n_final_pol = len(final_pol_flat) // FIELD_EXTENSION
    jproof['finalPol'] = []
    for i in range(n_final_pol):
        triplet = [int(final_pol_flat[i * FIELD_EXTENSION + j]) for j in range(FIELD_EXTENSION)]
        jproof['finalPol'].append(triplet)

    # Query indices
    query_indices = proof['query_indices']
    n_queries = len(query_indices)

    # Constant polynomial query values and siblings
    const_query_proofs = proof['const_query_proofs']
    jproof['s0_valsC'] = []
    jproof['s0_siblingsC'] = []
    for qp in const_query_proofs:
        # Values: flatten list of columns
        vals = []
        for col_vals in qp.v:
            vals.extend([int(v) for v in col_vals])
        jproof['s0_valsC'].append(vals)

        # Siblings: already structured as list of levels
        siblings = []
        for level in qp.mp:
            siblings.append([int(s) for s in level])
        jproof['s0_siblingsC'].append(siblings)

    # Stage query values and siblings
    stage_query_proofs = proof['stage_query_proofs']
    for stage_num, stage_proofs in stage_query_proofs.items():
        vals_key = f's0_vals{stage_num}'
        siblings_key = f's0_siblings{stage_num}'
        jproof[vals_key] = []
        jproof[siblings_key] = []

        for qp in stage_proofs:
            # Values
            vals = []
            for col_vals in qp.v:
                vals.extend([int(v) for v in col_vals])
            jproof[vals_key].append(vals)

            # Siblings
            siblings = []
            for level in qp.mp:
                siblings.append([int(s) for s in level])
            jproof[siblings_key].append(siblings)

    # Last level nodes
    last_level_nodes = proof.get('last_level_nodes', {})

    # Constant tree last levels
    if 'const' in last_level_nodes:
        nodes = last_level_nodes['const']
        # Reshape to [node_idx][hash_element]
        n_nodes = len(nodes) // HASH_SIZE
        jproof['s0_last_levelsC'] = []
        for i in range(n_nodes):
            jproof['s0_last_levelsC'].append([int(nodes[i * HASH_SIZE + j]) for j in range(HASH_SIZE)])

    # Stage tree last levels
    for stage_num in range(1, stark_info.nStages + 2):
        key = f'cm{stage_num}'
        if key in last_level_nodes:
            nodes = last_level_nodes[key]
            n_nodes = len(nodes) // HASH_SIZE
            jproof[f's0_last_levels{stage_num}'] = []
            for i in range(n_nodes):
                jproof[f's0_last_levels{stage_num}'].append([int(nodes[i * HASH_SIZE + j]) for j in range(HASH_SIZE)])

    # FRI step data
    for step_idx in range(len(fri_proof.fri_roots)):
        step = step_idx + 1  # FRI steps are 1-indexed in proof

        # Root
        jproof[f's{step}_root'] = [int(r) for r in fri_proof.fri_roots[step_idx]]

        # Query values and siblings
        jproof[f's{step}_vals'] = []
        jproof[f's{step}_siblings'] = []

        for qp in fri_proof.query_proofs[step_idx]:
            # Values: flatten
            vals = []
            for col_vals in qp.v:
                vals.extend([int(v) for v in col_vals])
            jproof[f's{step}_vals'].append(vals)

            # Siblings
            siblings = []
            for level in qp.mp:
                siblings.append([int(s) for s in level])
            jproof[f's{step}_siblings'].append(siblings)

        # Last level nodes for FRI
        fri_key = f'fri{step_idx}'
        if fri_key in last_level_nodes:
            nodes = last_level_nodes[fri_key]
            n_nodes = len(nodes) // HASH_SIZE
            jproof[f's{step}_last_levels'] = []
            for i in range(n_nodes):
                jproof[f's{step}_last_levels'].append([int(nodes[i * HASH_SIZE + j]) for j in range(HASH_SIZE)])

    return jproof


class TestVerifierE2E:
    """End-to-end verifier tests."""

    @pytest.mark.parametrize("air_name", ['simple', 'lookup', 'permutation'])
    def test_verify_valid_proof(self, air_name):
        """Test that stark_verify returns True for valid Python-generated proofs."""
        vectors = load_test_vectors(air_name)
        if vectors is None:
            pytest.skip(f"Test vectors not found for {air_name}")

        setup_ctx = load_setup_ctx(air_name)
        if setup_ctx is None:
            pytest.skip(f"Setup files not found for {air_name}")

        stark_info = setup_ctx.stark_info

        # Create params first to build verkey
        params = create_params_from_vectors(stark_info, vectors)

        # Build verkey (constant tree root) before proof generation
        # because the prover transcript needs it added first
        from protocol.stages import Starks
        from primitives.ntt import NTT

        N = 1 << stark_info.starkStruct.nBits
        N_ext = 1 << stark_info.starkStruct.nBitsExt
        ntt = NTT(N)

        starks = Starks(setup_ctx)
        verkey = starks.build_const_tree(params.constPolsExtended)

        # Create fresh transcript matching verifier expectations
        # The verifier in non-VADCOP mode adds: verkey, publicInputs, root1, ...
        transcript = Transcript(
            arity=stark_info.starkStruct.transcriptArity,
            custom=stark_info.starkStruct.merkleTreeCustom
        )
        transcript.put(verkey)  # Verifier adds this first

        # Generate proof in recursive mode (adds publicInputs and roots to transcript)
        print(f"\nGenerating proof for {air_name}...")
        proof = gen_proof(setup_ctx, params, transcript=transcript, recursive=True)
        print(f"DEBUG: Prover evals (first 9): {proof['evals'][:9]}")

        # Print prover's xi challenge for comparison
        from protocol.setup_ctx import FIELD_EXTENSION
        for i, ch_map in enumerate(stark_info.challengesMap):
            if ch_map.stage == stark_info.nStages + 2 and ch_map.stageId == 0:
                prover_xi = params.challenges[i * FIELD_EXTENSION:(i + 1) * FIELD_EXTENSION]
                print(f"DEBUG prover xi_challenge (idx={i}): {list(prover_xi)}")
                break

        # Convert proof to jproof format
        # We need the Starks instance to access trees, but gen_proof creates its own
        # For now, we'll reconstruct the jproof from the proof dict
        jproof = proof_to_jproof(proof, stark_info, starks)

        # Verify the proof (recursive mode uses verkey, not VADCOP global_challenge)
        print(f"Verifying proof for {air_name}...")
        result = stark_verify(
            jproof=jproof,
            setup_ctx=setup_ctx,
            verkey=verkey,
            publics=params.publicInputs,
        )

        assert result is True, f"Valid proof for {air_name} should verify"

    @pytest.mark.parametrize("air_name", ['simple'])
    def test_verify_corrupted_root_fails(self, air_name):
        """Test that stark_verify returns False for proofs with corrupted roots."""
        vectors = load_test_vectors(air_name)
        if vectors is None:
            pytest.skip(f"Test vectors not found for {air_name}")

        setup_ctx = load_setup_ctx(air_name)
        if setup_ctx is None:
            pytest.skip(f"Setup files not found for {air_name}")

        stark_info = setup_ctx.stark_info

        # Create params and build verkey
        params = create_params_from_vectors(stark_info, vectors)
        from protocol.stages import Starks
        starks = Starks(setup_ctx)
        verkey = starks.build_const_tree(params.constPolsExtended)

        # Create transcript with verkey
        transcript = Transcript(
            arity=stark_info.starkStruct.transcriptArity,
            custom=stark_info.starkStruct.merkleTreeCustom
        )
        transcript.put(verkey)

        # Generate proof in recursive mode
        proof = gen_proof(setup_ctx, params, transcript=transcript, recursive=True)

        # Convert to jproof
        jproof = proof_to_jproof(proof, stark_info, starks)

        # Corrupt root1
        jproof_corrupted = dict(jproof)
        jproof_corrupted['root1'] = [0, 0, 0, 0]  # Invalid root

        # Verify should fail
        result = stark_verify(
            jproof=jproof_corrupted,
            setup_ctx=setup_ctx,
            verkey=verkey,
            publics=params.publicInputs,
        )

        assert result is False, "Proof with corrupted root1 should fail verification"


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
